{
    # image encoder settings
    encoder_name: 'nfresnet50',
    image_seq_len: 2,
    freeze_img_encoder: False,
    adapter_config: {"mlp": {"adapter_type": "normal", "downsample_factor": 4}},

    # train settings 
    batch_size: 256,
    train_steps: 150000,
    lr_decay_iters: 300000,
    image_enc_lr: 3.0e-4, # lr from frozen paper
    lr: 8.0e-4,
    use_image_embed_layernorm: true,
    image_embed_dropout_prob: 0.1, 
    freeze_img_encoder_batchnorms: false,

    gradient_accumulation_steps: 8,
    zero_stage: 2,
    gradient_clipping: 1.0,

    # dataset / save / load settings
    train_dataset_name: 'conceptual_captions',
    train_dataset_dir: '/mnt/localdisk/conceptual_captions',
    eval_dataset_name: 'coco',
    eval_dataset_dir: '/mnt/localdisk/coco_data',
    vqa_dir: "/mnt/localdisk/vqa",
    gqa_dir: "/mnt/localdisk/gqa",

    save: "/mnt/localdisk/checkpoints/multimodal_transformer_nfresnet_adapters_baseline",
    load: "/mnt/localdisk/checkpoints/multimodal_transformer_nfresnet_adapters_baseline",
    
    wandb_project: "multimodal_ablations",
    eval_every: 100,

}